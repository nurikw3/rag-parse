# ğŸ§  RAG-Parse Chat

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95-green?logo=fastapi)
![LangChain](https://img.shields.io/badge/LangChain-0.1-purple)

A **Retrieval-Augmented Generation (RAG) system** for answering questions based on custom documents.  
Built with **LangChain**, **Chroma**, **BeautifulSoup**, **FastAPI**, **Streamlit**, and **Docker Compose**.  

---

## âœ¨ Features

- ğŸ’¬ Interactive chat interface with **Streamlit**  
- ğŸ“š Document retrieval using **LangChain + Chroma embeddings**  
- ğŸ¤– Supports multiple LLM models: DeepSeek, OpenAI, K2-Think  
- âš¡ Backend powered by **FastAPI**  
- ğŸ”’ Safe API key storage using **environment variables (.env)**  
- ğŸ³ Fully containerized with **Docker Compose**  

---

## ğŸ–¼ Screenshots

**Writing Code (`show.jpg`)**  
![Code Example](show.jpg)

**Frontend (`app.jpg`)**  
![Frontend](app.jpg)

---

## ğŸ›  Tech Stack

- Python 3.10  
- LangChain  
- Chroma (vector database)  
- BeautifulSoup (bs4)  
- FastAPI  
- Streamlit  
- Docker Compose  

---

## âš™ï¸ Setup

1. Clone the repository:

```bash
git clone <your-repo-url>
cd RAG-start
````

2. Create a `.env` file:

```env
LLM=your_api_token_here
```

> **Important:** Do not commit this file; add it to `.gitignore`.

3. Build and run with Docker Compose:

```bash
docker compose up --build
```

* ğŸŒ Frontend (Streamlit): [http://localhost:8501](http://localhost:8501)
* âš¡ Backend (FastAPI): [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“ Usage

1. Open **Streamlit** in your browser
2. Select a model from the sidebar
3. Ask a question in the chat input
4. The system retrieves relevant documents and generates a response using the selected LLM

---

## ğŸ“‚ Project Structure

```
RAG-start/
â”œâ”€ api.py                 # API key helper
â”œâ”€ streamlit_app.py       # Streamlit frontend
â”œâ”€ query_rag.py           # FastAPI backend
â”œâ”€ rag_data.py            # Embeddings & Chroma vector DB
â”œâ”€ Dockerfile.api         # Backend Dockerfile
â”œâ”€ Dockerfile.streamlit   # Frontend Dockerfile
â”œâ”€ docker-compose.yml     # Docker Compose setup
â”œâ”€ chroma_db/             # Persisted vector database
â”œâ”€ show.jpg               # Screenshot of coding process
â”œâ”€ app.jpg                # Screenshot of frontend
â”œâ”€ requirements.txt       # Python dependencies
â”œâ”€ .env                   # Environment variables (not in repo)
```

---

## ğŸ” Security

* API keys are **never hardcoded**
* Use `.env` files and Docker environment variables

---

## ğŸ’¡ Notes

* Works with multiple LLMs
* Fully containerized
* Designed for **rapid prototyping** and **RAG experimentation**
* Easy to share and deploy for collaborators

---

## ğŸš€ Contribution

Contributions are welcome! Please fork the repo, create a feature branch, and submit a pull request.

---

## ğŸ“« Contact

Created by **@nurikw3 (tg)** â€“ feel free to reach out for questions or collaborations.
